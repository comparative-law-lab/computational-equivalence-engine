[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.18458582.svg)](https://doi.org/10.5281/zenodo.18458582)
# Computational Equivalence Engine

**Official Implementation of the Computational Equivalence Methodology**

[![License](https://img.shields.io/badge/License-Academic%20Use%20Only-blue.svg)](https://zenodo.org/records/18119046)
[![Python](https://img.shields.io/badge/Python-3.8%2B-green.svg)](https://www.python.org/)
[![Status](https://img.shields.io/badge/Status-Validated-brightgreen.svg)]()

## Overview

The Computational Equivalence Engine is a validated implementation of the methodology described in:

> **King, Jason C. (2026).** *Computational Equivalence: A Structured Lab Methodology for Comparative Law in the Age of Artificial Intelligence* (Working Paper v3.0).  
> Available at: https://zenodo.org/records/18119046

This tool provides a standardized, algorithmic framework for measuring legal similarity across different jurisdictions on a 31-point scale (0.0-3.0).

---

## ğŸ¯ What This Does

Calculates **Legal Distance Scores** between legal concepts from different jurisdictions:

- **d = 0.0** â†’ Total Equivalent (perfect match)
- **d = 0.1-1.9** â†’ Functional Equivalent (same outcome, different form)
- **d = 2.0-2.9** â†’ Partial Equivalent (shared features, divergent outcomes)
- **d = 3.0** â†’ No Direct Equivalent (unique to jurisdiction)

**Example:**
```
Comparing: "Stare Decisis" (United States) vs "Jurisprudencia" (Spain)
Result: d = 1.0 (Standard Functional Equivalent)
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ README.md                                          # This file
â”œâ”€â”€ computational_equivalence_engine.py                # Standalone Python script
â”œâ”€â”€ Computational_Equivalence_Engine_EMBEDDED.ipynb   # Google Colab notebook (recommended)
â”œâ”€â”€ TECHNICAL_INTEGRITY_MEMORANDUM_FOR_SIGNATURE.docx # Audit certification
â”œâ”€â”€ TECHNICAL_INTEGRITY_AUDIT_COMPLETE.txt            # Validation report
â”œâ”€â”€ NUMERICAL_CALIBRATION_ALIGNMENT.txt               # Page 29 verification
â””â”€â”€ DELIVERY_README.txt                               # Contract deliverables summary
```

---

## ğŸš€ Quick Start

### **Option 1: Google Colab (Recommended - No Installation)**

1. **Open the notebook:**
   - Upload `Computational_Equivalence_Engine_EMBEDDED.ipynb` to [Google Colab](https://colab.research.google.com/)
   - Or click: **File â†’ Upload Notebook**

2. **Run the cells:**
   - Click **Runtime â†’ Run All**
   - Or run cells individually with the play button â–¶

3. **Use the form:**
   - Fill in your legal concepts in the interactive form
   - Click the play button on the form cell
   - Results appear immediately

**That's it!** No Python installation or file management required.

---

### **Option 2: Local Python Script**

**Requirements:**
- Python 3.8+
- pandas
- numpy

**Installation:**
```bash
pip install pandas numpy
```

**Usage:**
```python
from computational_equivalence_engine import (
    ComputationalEquivalenceEngine,
    LegalConcept,
    FunctionalTest
)

# Initialize
engine = ComputationalEquivalenceEngine()

# Define concepts
concept_a = LegalConcept(
    name="Stare Decisis",
    jurisdiction="United States",
    constituent_elements=["binding precedent", "vertical hierarchy", "case law"],
    regulatory_objective="Ensure legal uniformity and predictability"
)

concept_b = LegalConcept(
    name="Jurisprudencia",
    jurisdiction="Spain",
    constituent_elements=["binding precedent", "vertical hierarchy", "statutory interpretation"],
    regulatory_objective="Ensure legal uniformity and predictability"
)

# Define functional test
test = FunctionalTest(
    fact_pattern="Standard precedent application in lower courts",
    reliability_rate=0.92,
    procedural_friction="standard",
    iteration_threshold=2
)

# Analyze
result = engine.analyze(concept_a, concept_b, test)

# Results
print(f"Distance Score: {result.distance_score}")
print(f"Classification: {result.level.value}")
print(f"Rationale: {result.rationale}")
```

---

## ğŸ“Š Validation Status

### **Technical Integrity Audit: âœ… VERIFIED**

| Metric | Status | Details |
|--------|--------|---------|
| **Test Pass Rate** | 100% | 16/16 tests passed |
| **Real Cases** | âœ… Validated | 4/4 pilot cases correct |
| **Synthetic Tests** | âœ… Validated | 12/12 boundary tests passed |
| **Mathematical Formulas** | âœ… Verified | V_legal calculation correct |
| **ALCOA+ Standards** | âœ… Confirmed | Attributable, Accurate, Original |
| **Gate Verification** | âœ… Complete | All 4 logic gates validated |
| **Numerical Calibration** | âœ… Aligned | Page 29 specifications met |

**Certified by:** Dr. Lars Henrik Daehli Skjolding (Principal Data Scientist)  
**Date:** February 1, 2026

See: `TECHNICAL_INTEGRITY_AUDIT_COMPLETE.txt` for full details.

---

## ğŸ”¬ How It Works

### **Three-Step Decision Tree:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Partial Equivalency Test                   â”‚
â”‚ (Core Feature Filter)                               â”‚
â”‚                                                     â”‚
â”‚ Question: Do concepts share morphology OR teleology?â”‚
â”‚   â”œâ”€ NO  â†’ d=3.0 (No Direct Equivalent) [STOP]    â”‚
â”‚   â””â”€ YES â†’ Provisional score d=2.0-2.9 [CONTINUE]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Functional Equivalency Test                â”‚
â”‚ (Same Outcome Filter)                               â”‚
â”‚                                                     â”‚
â”‚ Question: Same practical outcome â‰¥85% reliability?  â”‚
â”‚   â”œâ”€ NO  â†’ Keep Partial d=2.0-2.9 [STOP]          â”‚
â”‚   â””â”€ YES â†’ Promote to Functional d=0.1-1.9 [CONTINUE]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Total Equivalency Test                     â”‚
â”‚ (Perfect Substitution Filter)                       â”‚
â”‚                                                     â”‚
â”‚ Question: Perfect doctrinal substitutability?       â”‚
â”‚   â”œâ”€ NO  â†’ Keep Functional d=0.1-1.9 [FINAL]      â”‚
â”‚   â””â”€ YES â†’ d=0.0 (Total Equivalent) [FINAL]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Subroutines:**

1. **`step_1_partial_equivalency_test()`**
   - Tests morphology overlap
   - Tests teleology match
   - Prevents category errors

2. **`step_2_functional_equivalency_test()`**
   - Evaluates reliability rate (85%, 90%, 95% thresholds)
   - Applies friction profiles (low/standard/high)
   - Determines functional equivalence

3. **`step_3_total_equivalency_test()`**
   - Tests perfect substitutability
   - Rare cases only (d=0.0)

4. **`_calculate_confidence_interval()`**
   - Maps to precise decimal scores
   - Handles Constitutional (d=0.15) vs Plenary (d=0.35) tiers
   - Applies procedural variables

---

## ğŸ“š Documentation

### **Core Files:**

- **`TECHNICAL_INTEGRITY_MEMORANDUM_FOR_SIGNATURE.docx`**  
  Formal certification document ready for signature and PDF conversion

- **`TECHNICAL_INTEGRITY_AUDIT_COMPLETE.txt`**  
  Complete audit checklist showing all requirements verified

- **`NUMERICAL_CALIBRATION_ALIGNMENT.txt`**  
  Verification that implementation matches methodology page 29 specifications

- **`DELIVERY_README.txt`**  
  Summary of contracted deliverables

### **Methodology Reference:**

For complete theoretical framework, see:
- King, J.C. (2026). *Computational Equivalence: A Structured Lab Methodology*
- Available: https://zenodo.org/records/18119046

---

## ğŸ“ Use Cases

### **Academic Research:**
- Comparative constitutional law studies
- Legal system convergence analysis
- Cross-jurisdictional harmonization research

### **Legal Translation:**
- Identifying functional equivalents for legal translation
- Validating terminology choices
- Preventing "false friends" errors

### **Policy Analysis:**
- Measuring legal convergence over time
- Tracking harmonization efforts (e.g., EU directives)
- Quantifying regulatory alignment

---

## âš ï¸ Important Warnings

### **ğŸš¨ CRITICAL: This is NOT Legal Advice**

1. **NO LEGAL AUTHORITY**  
   This software produces "Raw Algorithmic Output" with zero legal authority until validated by a qualified legal professional.

2. **MANDATORY SUPERVISION**  
   Under ABA Model Rules 5.1, 5.3, and Formal Opinion 512, attorney supervision is required.

3. **UNAUTHORIZED PRACTICE OF LAW**  
   Relying on this tool without verification by licensed counsel may constitute UPL.

4. **SCHOLARLY AUTHENTICATION REQUIRED**  
   All outputs must undergo the Scholarly Authentication Protocol before use in professional or academic contexts.

**By using this software, you agree you are solely responsible for verifying accuracy.**

---

## ğŸ“œ License

### **Methodology License:**
- **CC BY-NC-ND 4.0**  
- Non-commercial use only
- No derivatives of the methodology paper
- Citation required

### **Software License:**
- **Custom Academic/Non-Commercial**
- Copyright Â© 2026 Jason Charles King

### **You MAY:**
âœ… Use for academic review and research  
âœ… Modify for testing on new jurisdictions  
âœ… Validate the methodology

### **You MAY NOT:**
âŒ Commercial use  
âŒ Legal consultancy services  
âŒ Paid advisory without written permission

### **Citation Requirement:**
```
King, Jason C. (2026). Computational Equivalence: A Structured Lab Methodology 
for Comparative Law in the Age of Artificial Intelligence (Working Paper v3.0). 
Available at: https://zenodo.org/records/18119046
```

---

## ğŸ§ª Testing & Validation

### **Pilot Data (Real Cases):**

| Case ID | Comparison | Expected | Actual | Status |
|---------|------------|----------|--------|--------|
| US-ES-001 | Smiley v. Citibank vs Wizink | d=1.0 | d=1.0 | âœ… |
| US-ES-002 | Spanish Plenary (STS 367/2022) | d=0.35 | d=0.35 | âœ… |
| US-ES-003 | Constitutional Courts | d=0.15 | d=0.15 | âœ… |
| US-ES-004 | Pre-reiteration (STS 628/2015) | d=2.5 | d=2.5 | âœ… |

**Result:** 100% accuracy on real-world cases

### **Boundary Condition Tests:**

- âœ… 85% reliability threshold (weak functional)
- âœ… 90% reliability threshold (standard functional)
- âœ… 95% reliability threshold (strong functional)
- âœ… Low vs high friction differentiation
- âœ… N=1 vs Nâ‰¥2 iteration logic
- âœ… Category error prevention (d=3.0)

---

## ğŸ› ï¸ Technical Specifications

**Language:** Python 3.8+  
**Dependencies:** pandas, numpy (minimal)  
**Code Quality:**
- ~500 lines core algorithm
- Low cyclomatic complexity
- 100% decision path coverage
- Complete docstrings

**Performance:**
- Real-time classification (<1ms per case)
- Scales to thousands of comparisons
- Tested with production data

**Data Model:**
```python
@dataclass
class LegalConcept:
    name: str
    jurisdiction: str
    constituent_elements: List[str]  # Morphology
    regulatory_objective: str        # Teleology

@dataclass
class FunctionalTest:
    fact_pattern: str
    reliability_rate: float          # 0.0 to 1.0
    procedural_friction: str         # "low", "standard", "high"
    iteration_threshold: int         # 1 to 5

@dataclass
class EquivalenceResult:
    distance_score: float            # 0.0 to 3.0
    level: EquivalenceLevel
    confidence_interval: str
    rationale: str
    step_reached: int
```

---

## ğŸ¤ Support & Contact

### **Technical Implementation:**
**Dr. Lars Henrik Daehli Skjolding**  
Principal Data Scientist (External Contractor)  
On behalf of: Computational Comparative Law Lab

### **Legal Methodology:**
**Jason Charles King, JD**  
Email: jckingattorney@gmail.com

### **Reporting Issues:**
For technical issues or validation questions, please provide:
1. Your input parameters
2. Expected vs actual output
3. Error messages (if any)
4. Python version and dependencies

---

## ğŸ“ˆ Version History

**v1.0** (February 2026)
- Initial validated release
- 100% test pass rate (16/16)
- Technical integrity audit complete
- Page 29 numerical calibration verified
- Embedded Colab notebook created
- Legal disclaimer added

---

## ğŸ”® Future Development

**Potential Enhancements** (available separately):
- GUI application for non-technical users
- Batch processing for multiple cases
- CSV import/export functionality
- Standalone executable builds
- Integration with legal databases

Contact for custom development or enterprise licensing.

---

## ğŸ“‹ Frequently Asked Questions

### **Q: Is this ready for production use?**
A: Yes, for academic research. No, for autonomous legal advice. Attorney supervision required per ABA rules.

### **Q: Can I use this commercially?**
A: Not without written permission from the copyright holder.

### **Q: How accurate is it?**
A: 100% accuracy on pilot data (4/4 cases) and 100% on synthetic tests (12/12). Validated against real Supreme Court cases.

### **Q: Do I need to cite the methodology?**
A: Yes, citation is required for any publication using this software.

### **Q: Can I modify the code?**
A: Yes, for testing on new jurisdictions or academic validation. Not for commercial purposes.

### **Q: What's the difference between the .py and .ipynb files?**
A: The `.py` file is for local Python use. The `.ipynb` (Colab notebook) is easier for non-programmers - just click and use in your browser.

---

## ğŸ™ Acknowledgments

**Methodology:** Jason Charles King, JD  
**Technical Implementation:** Dr. Lars Henrik Daehli Skjolding  
**Validation Cases:** U.S. Supreme Court & Spanish Supreme Court databases  
**Platform:** Google Colab for accessible deployment

---

## ğŸ“„ Audit Trail

**Technical Integrity Memorandum:** Signed February 1, 2026  
**Status:** VERIFIED (without qualifications)  
**Certification:** Complete  
**Ready for Scholarly Authentication:** âœ… YES

---

**Last Updated:** February 2, 2026  
**Version:** 1.0  
**Status:** Production Ready (Academic Use)

---

*For the complete methodology, theoretical framework, and legal analysis, please refer to the original paper at https://zenodo.org/records/18119046*
